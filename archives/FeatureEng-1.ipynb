{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa9c827d",
   "metadata": {},
   "source": [
    "# Feature Engineering & Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95041d6",
   "metadata": {},
   "source": [
    "## 0. Setup & Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "35a201fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary libraries here\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "da3c35dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train and test data\n",
    "# !! use a relative path so that we don't need to change it each time we run on a different computer\n",
    "\n",
    "# load the training data\n",
    "train_path = '../data/train.csv'\n",
    "train_data = pd.read_csv(train_path)\n",
    "\n",
    "# load the testing data\n",
    "test_path = '../data/test-full.csv'\n",
    "test_data = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "9bb4a5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15120, 56)\n",
      "(581012, 55)\n"
     ]
    }
   ],
   "source": [
    "# quickly visualise the datasets\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "333f10ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242642</td>\n",
       "      <td>2881</td>\n",
       "      <td>130</td>\n",
       "      <td>22</td>\n",
       "      <td>210</td>\n",
       "      <td>54</td>\n",
       "      <td>1020</td>\n",
       "      <td>250</td>\n",
       "      <td>221</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>309891</td>\n",
       "      <td>3005</td>\n",
       "      <td>351</td>\n",
       "      <td>14</td>\n",
       "      <td>242</td>\n",
       "      <td>-16</td>\n",
       "      <td>1371</td>\n",
       "      <td>194</td>\n",
       "      <td>215</td>\n",
       "      <td>159</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>287847</td>\n",
       "      <td>3226</td>\n",
       "      <td>63</td>\n",
       "      <td>14</td>\n",
       "      <td>618</td>\n",
       "      <td>2</td>\n",
       "      <td>1092</td>\n",
       "      <td>232</td>\n",
       "      <td>210</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>516307</td>\n",
       "      <td>3298</td>\n",
       "      <td>317</td>\n",
       "      <td>8</td>\n",
       "      <td>661</td>\n",
       "      <td>60</td>\n",
       "      <td>752</td>\n",
       "      <td>198</td>\n",
       "      <td>233</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124860</td>\n",
       "      <td>3080</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>175</td>\n",
       "      <td>26</td>\n",
       "      <td>3705</td>\n",
       "      <td>219</td>\n",
       "      <td>227</td>\n",
       "      <td>144</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0  242642       2881     130     22                               210   \n",
       "1  309891       3005     351     14                               242   \n",
       "2  287847       3226      63     14                               618   \n",
       "3  516307       3298     317      8                               661   \n",
       "4  124860       3080      35      6                               175   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                              54                             1020   \n",
       "1                             -16                             1371   \n",
       "2                               2                             1092   \n",
       "3                              60                              752   \n",
       "4                              26                             3705   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  ...  Soil_Type32  \\\n",
       "0            250             221             88  ...            0   \n",
       "1            194             215            159  ...            0   \n",
       "2            232             210            107  ...            0   \n",
       "3            198             233            174  ...            0   \n",
       "4            219             227            144  ...            0   \n",
       "\n",
       "   Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0            0           1  \n",
       "1            0            0            0           1  \n",
       "2            0            0            0           1  \n",
       "3            0            0            0           1  \n",
       "4            0            0            0           1  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "f044f470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type31</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0   1       2596      51      3                               258   \n",
       "1   2       2590      56      2                               212   \n",
       "2   3       2804     139      9                               268   \n",
       "3   4       2785     155     18                               242   \n",
       "4   5       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  ...  Soil_Type31  \\\n",
       "0            221             232            148  ...            0   \n",
       "1            220             235            151  ...            0   \n",
       "2            234             238            135  ...            0   \n",
       "3            238             238            122  ...            0   \n",
       "4            220             234            150  ...            0   \n",
       "\n",
       "   Soil_Type32  Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type37  Soil_Type38  Soil_Type39  Soil_Type40  \n",
       "0            0            0            0            0  \n",
       "1            0            0            0            0  \n",
       "2            0            0            0            0  \n",
       "3            0            0            0            0  \n",
       "4            0            0            0            0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e237e56",
   "metadata": {},
   "source": [
    "## 1. Feature Engineering & Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b783324e",
   "metadata": {},
   "source": [
    "implemented so far (!!keep adding if you do stuff)\n",
    "\n",
    "**Feature engineering**\n",
    "++\n",
    "\n",
    "\n",
    "**Feature Selection**\n",
    "++\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebd33ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "b74fdf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interaction_features(df):\n",
    "    \"\"\"\n",
    "    Create interaction features by combining existing features.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to enhance with interaction features.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with new interaction features.\n",
    "    \"\"\"\n",
    "    # Example interaction: Elevation and Hydrology features\n",
    "    df['Elevation_plus_Vertical_Hydrology'] = df['Elevation'] + df['Vertical_Distance_To_Hydrology']\n",
    "    df['Elevation_times_Horizontal_Hydrology'] = df['Elevation'] * df['Horizontal_Distance_To_Hydrology']\n",
    "\n",
    "    # You can add more interactions based on domain knowledge and exploratory data analysis insights\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44de37d",
   "metadata": {},
   "source": [
    "### Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "eeaa030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ++ this fct does not seem to work when applied to train_data -> look into this\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def add_polynomial_features(df, feature_cols, degree=2):\n",
    "    \"\"\"\n",
    "    Adds polynomial features to the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to enhance with polynomial features.\n",
    "        feature_cols (list): List of column names to which polynomial features will be applied.\n",
    "        degree (int): The degree of the polynomial features.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with polynomial features added.\n",
    "    \"\"\"\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    poly_features = poly.fit_transform(df[feature_cols])\n",
    "    poly_feature_names = poly.get_feature_names(feature_cols)\n",
    "    df_poly = pd.DataFrame(poly_features, columns=poly_feature_names, index=df.index)\n",
    "    \n",
    "    # Drop the original features to avoid multicollinearity\n",
    "    df.drop(feature_cols, axis=1, inplace=True)\n",
    "    \n",
    "    # Concatenate the original DataFrame with the new polynomial features\n",
    "    df = pd.concat([df, df_poly], axis=1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a56f778",
   "metadata": {},
   "source": [
    "### Aggregate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "ecb03b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aggregate_features(df):\n",
    "    \"\"\"\n",
    "    Create aggregate features that summarize information across multiple features.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to enhance with aggregate features.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with new aggregate features.\n",
    "    \"\"\"\n",
    "    # Example aggregate feature: Mean Hillshade\n",
    "    df['Mean_Hillshade'] = df[['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']].mean(axis=1)\n",
    "\n",
    "    # More aggregates can be added based on exploratory data analysis and domain knowledge\n",
    "    # ++\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9cc68f",
   "metadata": {},
   "source": [
    "### Scale numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "8c8ce873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "def scale_numerical_columns(df):\n",
    "    # ++ add a definition of what this does\n",
    "    \n",
    "    df_scaled = df.copy()\n",
    "    \n",
    "    # List of columns not to be normalized\n",
    "    non_scaled_columns = ['Id', 'Cover_Type'] + [f'Soil_Type{i}' for i in range(1, 41)] + [f'Wilderness_Area{i}' for i in range(1, 5)]\n",
    "    \n",
    "    # List of columns to be normalized\n",
    "    scaled_columns = [col for col in df_scaled.columns if col not in non_scaled_columns]\n",
    "    \n",
    " \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    df_scaled[scaled_columns] = scaler.fit_transform(df_scaled[scaled_columns])\n",
    "    \n",
    "    return df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a55dcb9",
   "metadata": {},
   "source": [
    "### Integrating the Feature Engineering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "train_data = create_interaction_features(train_data)\n",
    "train_data = create_aggregate_features(train_data)\n",
    "train_data = scale_numerical_columns(train_data)\n",
    "\n",
    "# ++ this one does not work when applied to train_data (error)\n",
    "# train_data = add_polynomial_features(train_data, ['Elevation', 'Aspect', 'Slope'], degree=2)\n",
    "\n",
    "# test data\n",
    "test_data = create_interaction_features(test_data)\n",
    "test_data = create_aggregate_features(test_data)\n",
    "test_data = scale_numerical_columns(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e2ae1f",
   "metadata": {},
   "source": [
    "### Create euclidian distance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "7e909af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train after adding new features: (15120, 60)\n",
      "Shape of test after adding new features: (581012, 59)\n"
     ]
    }
   ],
   "source": [
    "# Calculate new features based on mean distances\n",
    "# train\n",
    "train_data['Mean_Elevation_Vertical_Distance_Hydrology'] = (train_data['Elevation'] + train_data['Vertical_Distance_To_Hydrology']) / 2\n",
    "train_data['Mean_Distance_Hydrology_Firepoints'] = (train_data['Horizontal_Distance_To_Hydrology'] + train_data['Horizontal_Distance_To_Fire_Points']) / 2\n",
    "train_data['Mean_Distance_Hydrology_Roadways'] = (train_data['Horizontal_Distance_To_Hydrology'] + train_data['Horizontal_Distance_To_Roadways']) / 2\n",
    "train_data['Mean_Distance_Firepoints_Roadways'] = (train_data['Horizontal_Distance_To_Fire_Points'] + train_data['Horizontal_Distance_To_Roadways']) / 2\n",
    "\n",
    "print(f\"Shape of train after adding new features: {train_data.shape}\")\n",
    "\n",
    "# test\n",
    "test_data['Mean_Elevation_Vertical_Distance_Hydrology'] = (test_data['Elevation'] + test_data['Vertical_Distance_To_Hydrology']) / 2\n",
    "test_data['Mean_Distance_Hydrology_Firepoints'] = (test_data['Horizontal_Distance_To_Hydrology'] + test_data['Horizontal_Distance_To_Fire_Points']) / 2\n",
    "test_data['Mean_Distance_Hydrology_Roadways'] = (test_data['Horizontal_Distance_To_Hydrology'] + test_data['Horizontal_Distance_To_Roadways']) / 2\n",
    "test_data['Mean_Distance_Firepoints_Roadways'] = (test_data['Horizontal_Distance_To_Fire_Points'] + test_data['Horizontal_Distance_To_Roadways']) / 2\n",
    "\n",
    "print(f\"Shape of test after adding new features: {test_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7f96e5",
   "metadata": {},
   "source": [
    "### Remove low correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "db3adff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed features with low correlation to 'Cover_Type': ['Elevation', 'Aspect', 'Horizontal_Distance_To_Hydrology', 'Hillshade_9am', 'Hillshade_3pm', 'Wilderness_Area2', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type11', 'Soil_Type13', 'Soil_Type14', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type30', 'Soil_Type34', 'Soil_Type36', 'Mean_Elevation_Vertical_Distance_Hydrology']\n",
      "Shape of train before removal: (15120, 60)\n",
      "Shape of train after removal: (15120, 28)\n",
      "Shape of test before removal: (581012, 59)\n",
      "Shape of test after removal: (581012, 27)\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = train_data.corr()  # Compute the correlation matrix\n",
    "\n",
    "# Calculate the correlation of each feature with 'Cover_Type'\n",
    "feature_correlation = correlation_matrix['Cover_Type'].drop(['Cover_Type', 'Id'])  # Exclude self-correlation and Id\n",
    "\n",
    "# Decide on a threshold for low correlation (example: below 0.02 in absolute value)\n",
    "low_correlation_features = feature_correlation[abs(feature_correlation) < 0.05].index.tolist()\n",
    "print(f\"Removed features with low correlation to 'Cover_Type': {low_correlation_features}\")\n",
    "\n",
    "\n",
    "# Drop these low correlation features from your dataset\n",
    "# train\n",
    "train = train_data.drop(low_correlation_features, axis=1)\n",
    "\n",
    "print(f\"Shape of train before removal: {train_data.shape}\")\n",
    "print(f\"Shape of train after removal: {train.shape}\")\n",
    "\n",
    "# test\n",
    "test = test_data.drop(low_correlation_features, axis=1)\n",
    "\n",
    "print(f\"Shape of test before removal: {test_data.shape}\")\n",
    "print(f\"Shape of test after removal: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2787ae66",
   "metadata": {},
   "source": [
    "### Merging Soil Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "4246eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract soil type columns\n",
    "soil_columns = [col for col in train.columns if col.startswith('Soil_Type')]\n",
    "\n",
    "# Combine the soil type columns into a single feature by identifying the active soil type\n",
    "# train\n",
    "train['Soil_Type_Combined'] = train[soil_columns].idxmax(axis=1).str.extract('(\\d+)').astype(int)\n",
    "train = train.drop(soil_columns, axis=1)\n",
    "\n",
    "# test\n",
    "test['Soil_Type_Combined'] = test[soil_columns].idxmax(axis=1).str.extract('(\\d+)').astype(int)\n",
    "test = test.drop(soil_columns, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb295ad",
   "metadata": {},
   "source": [
    "# 2. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "cde1e3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15120, 14)\n",
      "(581012, 13)\n"
     ]
    }
   ],
   "source": [
    "# check what the train and test shapes looks like with feature engineering implemented\n",
    "# train should have one more column (the Cover_Type) compared to test\n",
    "print(train.shape) \n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab2cf1",
   "metadata": {},
   "source": [
    "### Train the model(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebdeea9",
   "metadata": {},
   "source": [
    "Split the datasets for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "7a86ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for the prediction\n",
    "X = train.drop(['Id', 'Cover_Type'], axis=1)\n",
    "y = train['Cover_Type']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fdaa13",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "357ac7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.826058201058201\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = rf_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf = accuracy_score(y_val, y_pred)\n",
    "print(f'Random Forest Accuracy: {accuracy_rf}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18622cad",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "3cf1c8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Accuracy: 0.7040343915343915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Gradient Boosting Classifier\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_gb = gb_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_gb = accuracy_score(y_val, y_pred_gb)\n",
    "print(f'Gradient Boosting Classifier Accuracy: {accuracy_gb}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc21935",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "13fbabe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ++"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18cf116",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "f9ade75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ++"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c26c1df",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "4fc2216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ++"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4a5148",
   "metadata": {},
   "source": [
    "### Create the CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec16d7fd",
   "metadata": {},
   "source": [
    "Your submission should be a CSV file with 581012 rows and a header. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "db366e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test data by removing the 'Id' column\n",
    "X_test = test.drop(['Id'], axis=1)\n",
    "\n",
    "# Predict on the test data\n",
    "# !! change the model name according to what you are using\n",
    "test_predictions = gb_model.predict(X_test)\n",
    "\n",
    "# Create a DataFrame with 'Id' and 'Cover_Type' columns\n",
    "prediction_df = pd.DataFrame({\n",
    "    'Id': test['Id'],\n",
    "    'Cover_Type': test_predictions\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "prediction_filename = 'test_predictions.csv'\n",
    "prediction_df.to_csv(prediction_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "c8b215bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581012, 2)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this for debugging: it should output (581012, 2). Otherwise the format is wrong.\n",
    "prediction_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c645b1",
   "metadata": {},
   "source": [
    "## Scorekeeping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a731a4",
   "metadata": {},
   "source": [
    "To keep track of our Kaggle scores, every time you submit a new csv to kaggle, add the score + a short description of what we changed/added\n",
    "\n",
    "Use Format: Score obtained on kaggle / Feature Engineering Steps Used / Model Used\n",
    "!! keep in order of biggest to smallest scores\n",
    "\n",
    "**Random Forest**\n",
    "- 0.68 / Euclidian Dist, Low Corr(0.05), Merge Soil Types / Random Forest\n",
    "- 0.50 / Interaction Fct, Aggregate Fct, Euclidian Dist, Low Corr(0.05), Merge Soil Types / Random Forest\n",
    "\n",
    "\n",
    "**Gradient Boosting Classifier**\n",
    "- 0.65 / Euclidian Dist, Low Corr(0.02) / GBC\n",
    "- 0.56 / Euclidian Dist, Low Corr(0.05), Merge Soil Types / GBC\n",
    "- 0.55 / Euclidian Dist, Low Corr(0.05) / GBC\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9038b11c",
   "metadata": {},
   "source": [
    "# 3. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "e8e04671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ++ to do for the following models\n",
    "# Random Forest, XGBoost, Logistic Regression ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed28add4",
   "metadata": {},
   "source": [
    "# 4. Archives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba66451",
   "metadata": {},
   "source": [
    "Drag code here that might be useful later but that currently does not work/ cannot be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "22b69372",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ++ gives very bad accuracy scores (around 0.3) for all the algos, so sth is wrong\n",
    "\n",
    "# test model\n",
    "\n",
    "\n",
    "from ast import literal_eval\n",
    "from catboost import CatBoostClassifier\n",
    "#from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_models(X, y):\n",
    "    models = {\n",
    "        \"LogReg\": LogisticRegression(),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"SVM\": SVC(),\n",
    "        \"DT\": DecisionTreeClassifier(),\n",
    "        \"RF\": RandomForestClassifier(),\n",
    "        \"ExtraTrees\": ExtraTreesClassifier(),\n",
    "        \"XGB\": XGBClassifier(),\n",
    "        \"Catboost\": CatBoostClassifier(verbose=0),\n",
    "        #\"LightGBM\": LGBMClassifier(),\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        scores = cross_val_score(model, X, y, cv=5, scoring='accuracy') \n",
    "        results[name] = scores\n",
    "        print(f\"{name}: Accuracy = {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "    \n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
